{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Linking Accuracy Metric (SLAM):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_json_file(file_path):\n",
    "    # Load the JSON data from the file\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    df_dev_set = pd.DataFrame(json_data, columns=[\"question_id\", \"db_id\", \"tables\"])\n",
    "\n",
    "    #df_dev_set.head()\n",
    "    return df_dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to import a CSV file into a pandas DataFrame with the given schema\n",
    "def import_csv_file(file_path):\n",
    "    # Define a custom converter to parse the string representation of lists\n",
    "    def parse_list(x):\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    # Specify the column data types\n",
    "    dtype_dict = {\n",
    "        'question_id': int,\n",
    "        'tables': str,\n",
    "        'gen_tables': str,\n",
    "        'total_tables': int\n",
    "    }\n",
    "\n",
    "    # Specify the converters for list columns\n",
    "    converters = {\n",
    "        'tables': parse_list,\n",
    "        'gen_tables': parse_list\n",
    "    }\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path, dtype=dtype_dict, converters=converters)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compare tables from dev and gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lists(ground_truth, predicted):\n",
    "    # Initialize variables for TP, TN, FP, and FN\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    true_positives = len(set(ground_truth) & set(predicted))\n",
    "    false_positives = len(set(predicted) - set(ground_truth))\n",
    "    false_negatives = len(set(ground_truth) - set(predicted))\n",
    "    true_negatives = 0  # Not applicable for this scenario\n",
    "\n",
    "    return true_positives, true_negatives, false_positives, false_negatives\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_19788\\3436437724.py:25: ParserWarning: Both a converter and dtype were specified for column tables - only the converter will be used.\n",
      "  df = pd.read_csv(file_path, dtype=dtype_dict, converters=converters)\n",
      "C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_19788\\3436437724.py:25: ParserWarning: Both a converter and dtype were specified for column gen_tables - only the converter will be used.\n",
      "  df = pd.read_csv(file_path, dtype=dtype_dict, converters=converters)\n",
      "C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_19788\\822853818.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_df = pd.concat([final_df, pd.DataFrame([metrics_dict])], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>tables_dev</th>\n",
       "      <th>tables_csv</th>\n",
       "      <th>gen_tables</th>\n",
       "      <th>total_tables</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>[frpm]</td>\n",
       "      <td>[frpm]</td>\n",
       "      <td>[frpm, Grapes, Lemon]</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>[frpm, schools]</td>\n",
       "      <td>[Orange, Mango, Strawberry]</td>\n",
       "      <td>[Apple, Blueberry, Pineapple]</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>[frpm, schools]</td>\n",
       "      <td>[Grapes, Kiwi, Peach]</td>\n",
       "      <td>[Lemon, Banana, Cherry]</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>[frpm, schools]</td>\n",
       "      <td>[Blueberry, Pear, Watermelon]</td>\n",
       "      <td>[Mango, Strawberry, Apple]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>california_schools</td>\n",
       "      <td>[satscores, schools]</td>\n",
       "      <td>[Pineapple, Lime, Raspberry]</td>\n",
       "      <td>[Kiwi, Grapes, Peach]</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_id               db_id            tables_dev  \\\n",
       "0           1  california_schools                [frpm]   \n",
       "1           2  california_schools       [frpm, schools]   \n",
       "2           3  california_schools       [frpm, schools]   \n",
       "3           4  california_schools       [frpm, schools]   \n",
       "4           5  california_schools  [satscores, schools]   \n",
       "\n",
       "                      tables_csv                     gen_tables total_tables  \\\n",
       "0                         [frpm]          [frpm, Grapes, Lemon]           12   \n",
       "1    [Orange, Mango, Strawberry]  [Apple, Blueberry, Pineapple]           17   \n",
       "2          [Grapes, Kiwi, Peach]        [Lemon, Banana, Cherry]           25   \n",
       "3  [Blueberry, Pear, Watermelon]     [Mango, Strawberry, Apple]            8   \n",
       "4   [Pineapple, Lime, Raspberry]          [Kiwi, Grapes, Peach]           36   \n",
       "\n",
       "  tp tn fp fn  precision  recall  f1_score  \n",
       "0  1  0  2  0   0.333333     1.0       0.5  \n",
       "1  0  0  3  2   0.000000     0.0       0.0  \n",
       "2  0  0  3  2   0.000000     0.0       0.0  \n",
       "3  0  0  3  2   0.000000     0.0       0.0  \n",
       "4  0  0  3  2   0.000000     0.0       0.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = import_json_file('dev/dev.json') \n",
    "#df1.head()\n",
    "df2 = import_csv_file('gen_tables.csv')\n",
    "#df2.head()\n",
    "merged_df = df1.merge(df2, on='question_id', how='inner')\n",
    "merged_df = merged_df.rename(columns={'tables_x': 'tables_dev', 'tables_y': 'tables_csv'})\n",
    "\n",
    "merged_df.head()\n",
    "\n",
    "final_df = pd.DataFrame(columns=['question_id','db_id','tables_dev','tables_csv','gen_tables','total_tables','tp','tn','fp','fn','precision','recall','f1_score'])\n",
    "\n",
    "for index, row in enumerate(merged_df.iterrows()):\n",
    "    row = row[1]\n",
    "    #row2 = row2[1]\n",
    "    tp, tn, fp, fn = compare_lists(row['tables_dev'], row['gen_tables'])\n",
    "\n",
    "\n",
    "    # Calculate precision, recall, and F1 score for each row\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0.0\n",
    "    else:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    #print('question_id: ',row['question_id'],'|| gen_tables:',row['gen_tables'],'|| true_tables:',row['tables_dev'])\n",
    "    #print(\"True Positives:\", tp)\n",
    "    #print(\"True Negatives:\", tn)\n",
    "    #print(\"False Positives:\", fp)\n",
    "    #print(\"False Negatives:\", fn)\n",
    "    #print(\"Precision:\", precision)\n",
    "    #print(\"Recall:\", recall)\n",
    "    #print(\"F1-Score:\", f1_score)\n",
    "    #print('-----------------------------------')\n",
    "\n",
    "    metrics_dict = {\n",
    "        'question_id': row['question_id'],\n",
    "        'db_id': row['db_id'],\n",
    "        'tables_dev': row['tables_dev'],\n",
    "        'tables_csv': row['tables_csv'],\n",
    "        'gen_tables': row['gen_tables'],\n",
    "        'total_tables': row['total_tables'],\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }\n",
    "\n",
    "    final_df = pd.concat([final_df, pd.DataFrame([metrics_dict])], ignore_index=True)\n",
    "\n",
    "final_df.to_csv('metrics_result.csv', index=False)\n",
    "final_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xcs224u_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
